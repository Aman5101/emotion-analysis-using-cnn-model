{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport librosa # audio processing\nfrom IPython.display import Audio # playing audio\nfrom matplotlib import pyplot as plt # plots\nimport librosa.display\n!pip install noisereduce\nimport noisereduce as nr\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D,BatchNormalization, MaxPooling1D, ReLU\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, ZeroPadding2D\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy, sparse_categorical_crossentropy\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input/speech-emotion-recognition-en/Crema'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-04T11:03:49.104148Z","iopub.execute_input":"2022-06-04T11:03:49.104434Z","iopub.status.idle":"2022-06-04T11:03:58.281874Z","shell.execute_reply.started":"2022-06-04T11:03:49.104401Z","shell.execute_reply":"2022-06-04T11:03:58.281043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"data = [] # the audio signal\nlabel = [] # the sentiment (for classification)\nmeta = [] # metadata (actor_sentence_sentiment_pitch)\nsampling_rate = 18000 # all of them should have the same sampling rate","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:03:58.284268Z","iopub.execute_input":"2022-06-04T11:03:58.284568Z","iopub.status.idle":"2022-06-04T11:03:58.289196Z","shell.execute_reply.started":"2022-06-04T11:03:58.28453Z","shell.execute_reply":"2022-06-04T11:03:58.288535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def play_plot(index):\n    print(meta[index])\n    Audio(data=data[index], rate=sampling_rate)\n    #fig, ax = plt.subplots(nrows=3, sharex=True)\n    #librosa.display.waveshow(data[index], sr=sampling_rate, ax=ax[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:03:58.29056Z","iopub.execute_input":"2022-06-04T11:03:58.290805Z","iopub.status.idle":"2022-06-04T11:03:58.302023Z","shell.execute_reply.started":"2022-06-04T11:03:58.290771Z","shell.execute_reply":"2022-06-04T11:03:58.301265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_length(time_series_list, length):\n    n = len(time_series_list)\n    for i in range(n):\n        audio_length = len(time_series_list[i])\n        if audio_length < length:\n            time_series_list[i] = np.append(time_series_list[i], [0 for i in range(length-audio_length)])\n        else:\n            time_series_list[i] = np.array(time_series_list[i][:length])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:03:58.305212Z","iopub.execute_input":"2022-06-04T11:03:58.305478Z","iopub.status.idle":"2022-06-04T11:03:58.313265Z","shell.execute_reply.started":"2022-06-04T11:03:58.305447Z","shell.execute_reply":"2022-06-04T11:03:58.312427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_for_nan(l):\n    for x in l:\n        if str(x) == 'nan':\n            return True\n    return False","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:03:58.315159Z","iopub.execute_input":"2022-06-04T11:03:58.315829Z","iopub.status.idle":"2022-06-04T11:03:58.32128Z","shell.execute_reply.started":"2022-06-04T11:03:58.315793Z","shell.execute_reply":"2022-06-04T11:03:58.320695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_dict = dict()\nemotions_dict['SAD'] = 0\nemotions_dict['ANG'] = 1\nemotions_dict['DIS'] = 2\nemotions_dict['FEA'] = 3\nemotions_dict['HAP'] = 4\nemotions_dict['NEU'] = 5","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:03:58.322449Z","iopub.execute_input":"2022-06-04T11:03:58.323246Z","iopub.status.idle":"2022-06-04T11:03:58.330104Z","shell.execute_reply.started":"2022-06-04T11:03:58.323204Z","shell.execute_reply":"2022-06-04T11:03:58.329404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Load to lists.. takes too long, run it just once''' \nlength_sum = 0\nlist_a = []\nlist_b = []\nfor dirname, _, filenames in os.walk('/kaggle/input/speech-emotion-recognition-en/Crema'):\n    for filename in filenames:\n        meta.append(filename[:-4])\n        full_filename = os.path.join(dirname, filename)\n        sentiment = filename.split('_')[2]\n        label.append(emotions_dict[sentiment])\n        signal, sr = librosa.load(full_filename, sr = sampling_rate)\n        reduced_noise = nr.reduce_noise(y=signal, sr=sampling_rate)\n        if not check_for_nan(reduced_noise):\n            signal = reduced_noise\n        data.append(signal)\n        length_sum += len(signal)\n        if (len(data)%100 == 0):\n            print(len(data), \" audio loaded\")\nn = len(data)\nadjust_length(data, 3*sampling_rate)\ndata = np.array(data)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:03:58.3313Z","iopub.execute_input":"2022-06-04T11:03:58.332018Z","iopub.status.idle":"2022-06-04T11:20:03.912813Z","shell.execute_reply.started":"2022-06-04T11:03:58.331982Z","shell.execute_reply":"2022-06-04T11:20:03.911849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display metadata, play audio and plot waveform","metadata":{}},{"cell_type":"code","source":"index = 5","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:03.914513Z","iopub.execute_input":"2022-06-04T11:20:03.9148Z","iopub.status.idle":"2022-06-04T11:20:03.921018Z","shell.execute_reply.started":"2022-06-04T11:20:03.914765Z","shell.execute_reply":"2022-06-04T11:20:03.92027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Audio(data=data[index], rate=sampling_rate)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:03.922255Z","iopub.execute_input":"2022-06-04T11:20:03.922993Z","iopub.status.idle":"2022-06-04T11:20:03.941867Z","shell.execute_reply.started":"2022-06-04T11:20:03.922944Z","shell.execute_reply":"2022-06-04T11:20:03.941225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,5))\nfig.suptitle(meta[index], fontsize=15)\nlibrosa.display.waveshow(data[index], sr=sampling_rate)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:03.944605Z","iopub.execute_input":"2022-06-04T11:20:03.945329Z","iopub.status.idle":"2022-06-04T11:20:04.345776Z","shell.execute_reply.started":"2022-06-04T11:20:03.945295Z","shell.execute_reply":"2022-06-04T11:20:04.344343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"def feature_extraction_1D(data):\n\n    # Zero Crossing rate\n    features = librosa.feature.zero_crossing_rate(y=data)\n\n    # Energy\n    features = np.append(features, librosa.feature.rms(y=data), axis=1)\n\n    # Mel-frequency cepstral coefficient\n    l = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), axis=0).reshape(1, 106)\n    features = np.append(features, l, axis=1)\n    \n    # Spectral Centroid\n    features = np.append(features, librosa.feature.spectral_centroid(y=data, sr=sampling_rate), axis=1)\n    \n    # Spectral Bandwidth\n    features = np.append(features, librosa.feature.spectral_bandwidth(y=data, sr=sampling_rate), axis=1)\n    \n    # Spectral Flatness\n    features = np.append(features, librosa.feature.spectral_flatness(y=data), axis=1)\n    \n    # Spectral Rolloff maximum frequencies\n    features = np.append(features, librosa.feature.spectral_rolloff(y=data, sr=sampling_rate), axis=1)\n    \n    # Spectral Rolloff minimum frequencies\n    features = np.append(features, librosa.feature.spectral_rolloff(y=data, sr=sampling_rate, roll_percent=0.01), axis=1)\n    \n    return np.array(features)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:04.347158Z","iopub.execute_input":"2022-06-04T11:20:04.347433Z","iopub.status.idle":"2022-06-04T11:20:04.356372Z","shell.execute_reply.started":"2022-06-04T11:20:04.34739Z","shell.execute_reply":"2022-06-04T11:20:04.355512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_features_extracted_1D = []\nfor i in range(n):\n    data_features_extracted_1D.append(np.squeeze(np.append(feature_extraction_1D(data[i]), label[i])))\n    if (len(data_features_extracted_1D)%100 == 0):\n            print(len(data_features_extracted_1D), \" entry processed\")\ndata_features_extracted_1D = np.array(data_features_extracted_1D)\nprint(data_features_extracted_1D.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:04.357807Z","iopub.execute_input":"2022-06-04T11:20:04.358077Z","iopub.status.idle":"2022-06-04T11:26:00.487092Z","shell.execute_reply.started":"2022-06-04T11:20:04.358043Z","shell.execute_reply":"2022-06-04T11:26:00.486326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"def split_1D(x,y):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state =1, stratify = y)\n    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.05, random_state =1, stratify = y_train)\n    return x_train, x_val, x_test, y_train, y_test, y_val","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:26:00.488531Z","iopub.execute_input":"2022-06-04T11:26:00.489012Z","iopub.status.idle":"2022-06-04T11:26:00.497088Z","shell.execute_reply.started":"2022-06-04T11:26:00.488974Z","shell.execute_reply":"2022-06-04T11:26:00.496094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, x_test, y_train, y_test, y_val = split_1D(data_features_extracted_1D, label)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:26:00.498876Z","iopub.execute_input":"2022-06-04T11:26:00.4994Z","iopub.status.idle":"2022-06-04T11:26:00.556089Z","shell.execute_reply.started":"2022-06-04T11:26:00.49932Z","shell.execute_reply":"2022-06-04T11:26:00.555201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1D Model","metadata":{}},{"cell_type":"code","source":"x_train = x_train[:,:,np.newaxis]\nx_val = x_val[:,:,np.newaxis]\nx_test = x_test[:,:,np.newaxis]","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:26:00.56114Z","iopub.execute_input":"2022-06-04T11:26:00.561575Z","iopub.status.idle":"2022-06-04T11:26:00.566155Z","shell.execute_reply.started":"2022-06-04T11:26:00.561538Z","shell.execute_reply":"2022-06-04T11:26:00.565208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\n\nmodel.add(Conv1D(input_shape=(x_train.shape[1], 1),filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling1D(pool_size=2, strides=2))\nmodel.add(Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling1D(pool_size=2, strides=2))\nmodel.add(Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling1D(pool_size=2, strides=2))\nmodel.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling1D(pool_size=2,strides=2))\nmodel.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling1D(pool_size=2,strides=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=6, activation=\"softmax\"))\n\nopt = optimizers.Adam()\nmodel.compile(optimizer=opt , loss = 'SparseCategoricalCrossentropy' , metrics = ['accuracy'])\ncheckpoint = ModelCheckpoint(\"checkpoint_1D.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n\nhistory=model.fit(np.array(x_train), np.array(y_train), epochs=150, validation_data=(np.array(x_val), np.array(y_val)), callbacks=[checkpoint, early])\nmodel.save(\"./best_model_1D\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:26:00.567723Z","iopub.execute_input":"2022-06-04T11:26:00.568179Z","iopub.status.idle":"2022-06-04T11:39:33.957241Z","shell.execute_reply.started":"2022-06-04T11:26:00.568143Z","shell.execute_reply":"2022-06-04T11:39:33.956314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:39:33.96383Z","iopub.execute_input":"2022-06-04T11:39:33.96616Z","iopub.status.idle":"2022-06-04T11:39:34.389854Z","shell.execute_reply.started":"2022-06-04T11:39:33.966111Z","shell.execute_reply":"2022-06-04T11:39:34.38818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_classes = model.predict(x_test)\npredicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n\ncorrect = np.where(predicted_classes==y_test)[0]\nprint (\"Found %d correct labels\" % len(correct))\n\nincorrect = np.where(predicted_classes!=y_test)[0]\nprint (\"Found %d incorrect labels\" % len(incorrect))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:39:34.391202Z","iopub.execute_input":"2022-06-04T11:39:34.391474Z","iopub.status.idle":"2022-06-04T11:39:35.323298Z","shell.execute_reply.started":"2022-06-04T11:39:34.391438Z","shell.execute_reply":"2022-06-04T11:39:35.322297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, predicted_classes))\nconf_mat = confusion_matrix(y_true=y_test, y_pred=predicted_classes)\nsns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap = 'ocean_r',xticklabels = list(emotions_dict.keys()),yticklabels = list(emotions_dict.keys()))\nprint('val accuracy:', max(val_accuracy)*100)\nprint('train accuracy:', max(accuracy)*100)\nprint(\"test accuracy\",(len(correct)*100/(len(correct)+len(incorrect))))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:39:35.32742Z","iopub.execute_input":"2022-06-04T11:39:35.327944Z","iopub.status.idle":"2022-06-04T11:39:35.834855Z","shell.execute_reply.started":"2022-06-04T11:39:35.327903Z","shell.execute_reply":"2022-06-04T11:39:35.83419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y= model.predict('/kaggle/input/speech-emotion-recognition-en/Crema/1001_DFA_HAP_XX')","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:06:33.773046Z","iopub.execute_input":"2022-06-04T12:06:33.77354Z","iopub.status.idle":"2022-06-04T12:06:34.311721Z","shell.execute_reply.started":"2022-06-04T12:06:33.773489Z","shell.execute_reply":"2022-06-04T12:06:34.309197Z"},"trusted":true},"execution_count":null,"outputs":[]}]}